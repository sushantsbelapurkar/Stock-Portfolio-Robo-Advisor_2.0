{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### DATABASE CONNECTION ####\n",
    "#####Load data function ####\n",
    "def saveToSQL(dataframe, tablename, todo):\n",
    "    from sqlalchemy import create_engine\n",
    "    if 'source' in dataframe.columns:\n",
    "        dataframe = dataframe.drop(columns=['source'])\n",
    "    if 'cik' in dataframe.columns:\n",
    "        dataframe = dataframe.drop(columns=['cik'])\n",
    "    else:\n",
    "        dataframe = dataframe\n",
    "    engine = create_engine('########### HIDDEN CODE #################')\n",
    "    dataframe.index = dataframe.index + 1\n",
    "    try:\n",
    "        dataframe.to_sql(tablename, con=engine, schema='mysql_portfolio', if_exists=todo, index=True, index_label='id', method=None)\n",
    "        # print(f\"data saved in {tablename} successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table or inserting data: {str(e)}\")\n",
    "\n",
    "print('Data connection successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from io import BufferedReader\n",
    "import mysql.connector as connection\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "\n",
    "pymysql.converters.encoders[np.float64] = pymysql.converters.escape_float\n",
    "pymysql.converters.conversions = pymysql.converters.encoders.copy()\n",
    "pymysql.converters.conversions.update(pymysql.converters.decoders)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "######### RUN BELOW CODE LINES ONCE TO LOAD BASE INFO FOR ALL EXCHANGES ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######### DROP EXISTING BASE TABLES ##########\n",
    "# import required data from mydql/database\n",
    "import mysql.connector as connection\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    mydb = connection.connect('########### HIDDEN CODE #################')\n",
    "    sql_statements = [\n",
    "        \"DROP TABLE IF EXISTS mysql_portfolio.symbol_list;\",\n",
    "         \n",
    "        \n",
    "        ########### HIDDEN CODE #################\n",
    "    ]\n",
    "    \n",
    "    # Execute each SQL statement\n",
    "    for sql in sql_statements:\n",
    "        mycursor = mydb.cursor()\n",
    "        mycursor.execute(sql)\n",
    "        print(f\"Executed: {sql}\")\n",
    "        mycursor.close()\n",
    "        \n",
    "except Exception as e:\n",
    "    mydb.close()\n",
    "    # print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### LOAD all symbols \n",
    "\n",
    "#### METHOD 2 TO READ DATA \n",
    "api_key = \"########### HIDDEN CODE #################\"\n",
    "df_symbol_list = pd.read_json(api_key)\n",
    "df_symbol_list['date_added']= date.today()\n",
    "# df_symbol_list.head(10)\n",
    "saveToSQL(df_symbol_list,\"symbol_list\",'replace')\n",
    "print('Entire Data loaded in table')\n",
    "# call_proc('insert_datetime_income_statemnent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "today = date.today()\n",
    "first_day_of_current_month = date(today.year, today.month, 1)\n",
    "last_day_of_previous_month = first_day_of_current_month - timedelta(days=1)\n",
    "\n",
    "# print(first_day_of_current_month - timedelta(days=1))\n",
    "\n",
    "last_month_end_string = last_day_of_previous_month.strftime(\"%Y-%m-%d\")\n",
    "last_month_end_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stock screener\n",
    "# UPDATE DAILY\n",
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "\n",
    "exchanges = [\"NYSE\", \"NASDAQ\", \"NSE\"]\n",
    "\n",
    "for exchange in exchanges:\n",
    "    api_key = '########### HIDDEN CODE #################'\n",
    "    df_stock_screener_usa = pd.read_json(api_key)\n",
    "    df_stock_screener_usa['date_added']= date.today()\n",
    "    saveToSQL(df_stock_screener_usa,\"stock_screener\",'append')\n",
    "    print('Entire Data loaded in table for '+exchange)\n",
    "#     df_income_statement.append(df_income_statement)\n",
    "#     call_api(newurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sector p/e \n",
    "\n",
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "\n",
    "exchanges = [\"NYSE\", \"NASDAQ\", \"NSE\"]\n",
    "\n",
    "for exchange in exchanges:\n",
    "    api_key = '####### HIDDEN CODE ############'\n",
    "    # print(api_key)\n",
    "    df_sectorpe_usa = pd.read_json(api_key)\n",
    "    df_sectorpe_usa['date_added']= date.today()\n",
    "    saveToSQL(df_sectorpe_usa,\"sector_pe\",'append')\n",
    "    print('Entire Data loaded in table for '+exchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Industry p/e\n",
    "# UPDATE BY PROVIDING MANUAL DATE\n",
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "\n",
    "exchanges = [\"NYSE\", \"NASDAQ\", \"NSE\"]\n",
    "\n",
    "for exchange in exchanges:\n",
    "    api_key = '############### HIDDEN CODE ################'\n",
    "    df_industrype_usa = pd.read_json(api_key)\n",
    "    df_industrype_usa['date_added']= date.today()\n",
    "    saveToSQL(df_industrype_usa,\"industry_pe\",'append')\n",
    "    print('Entire Data loaded in table for '+exchange)\n",
    "#     df_income_statement.append(df_income_statement)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "######### RUN BELOW CODE PER EXCHANGE PER SYMBOL ##########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######### CHANGE EXCHANGE FOR PER SYMBOL ##########\n",
    "# import required data from mydql/database\n",
    "import mysql.connector as connection\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    mydb = connection.connect(####### HIDDEN CODE ############)\n",
    "    query = \"SELECT * FROM mysql_portfolio.symbol_list WHERE exchangeShortName in ('NASDAQ') AND type = 'stock';\"\n",
    "    df_symbol_list_sql = pd.read_sql(query,mydb)\n",
    "#     df_symbol_list_sql.head(10)\n",
    "    symbol = df_symbol_list_sql['symbol']\n",
    "    \n",
    "    mydb.close() #close the connection\n",
    "except Exception as e:\n",
    "    mydb.close()\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_symbol_list_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pymysql\n",
    "import requests\n",
    "\n",
    "def connect_with_retry_1(api_url): \n",
    "    max_retries = 100\n",
    "    retry_delay = 65  # seconds\n",
    "    retries = 0\n",
    "    \n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = requests.get(api_url)\n",
    "            # print(response)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # if response.status_code == 429:\n",
    "            #     print(response.status_code)\n",
    "            #     make_http_request(api_url,response)\n",
    "            # else:\n",
    "            # print(\"try code execution\")\n",
    "            read_json = pd.read_json(api_url)\n",
    "            # read_json.raise_for_status()\n",
    "            return read_json\n",
    "        \n",
    "        except pymysql.err.OperationalError as e:\n",
    "            if e.args[0] == 1040:  # Too many connections error\n",
    "                print(\"Too many connections. Retrying in {} seconds...\".format(retry_delay))\n",
    "                time.sleep(retry_delay)\n",
    "                retries += 1\n",
    "            else:\n",
    "                raise  # Re-raise other OperationalError exceptions\n",
    "        \n",
    "        except requests.HTTPError as e:\n",
    "            if response.status_code == 429:\n",
    "                retry_after = int(response.headers.get('Retry-After', 0))\n",
    "                print(\"Wait time:\", retry_after)\n",
    "                time.sleep(retry_after)\n",
    "                retries += 1\n",
    "                return connect_with_retry(api_url)\n",
    "            else:\n",
    "                print(\"Error:\", e)\n",
    "    # If max_retries is reached without a successful connection, handle the failure\n",
    "    print(\"Failed to establish a database connection after {} retries.\".format(max_retries))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code to load shares float  - 1\n",
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "\n",
    "api_key = '######## HIDDEN CODE ##########'\n",
    "symbol = df_symbol_list_sql['symbol']\n",
    "\n",
    "for x in symbol:\n",
    "    newurl = api_key.replace('stock_name',x)\n",
    "    api_data = connect_with_retry(newurl)\n",
    "    df_share_float = api_data\n",
    "    df_share_float['date_added']= date.today()\n",
    "    saveToSQL(df_share_float,\"shares_float\",'append')\n",
    "#     df_income_statement.append(df_income_statement)\n",
    "#     call_api(newurl)\n",
    "print('Entire Data loaded in table')\n",
    "\n",
    "index_sql = \"CREATE INDEX idx_symbol ON mysql_portfolio.shares_float (symbol(255));\"\n",
    "\n",
    "constraint_sql = \"\"\"\n",
    "ALTER TABLE mysql_portfolio.shares_float\n",
    "ADD CONSTRAINT unique_shares_float UNIQUE (symbol,freeFloat,floatShares);\n",
    "\"\"\"\n",
    "# Database connection\n",
    "engine = create_engine('####### HIDDEN CODE ############')\n",
    "\n",
    "# Execute SQL statements\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(index_sql)\n",
    "    connection.execute(constraint_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Historical Prices\n",
    "# UPDATE BY PROVIDING MANUAL DATE\n",
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "\n",
    "# symbol = ['AAPL','MSFT','F','AMD','FB','MRF.NS','SHAKTIPUMP.NS','OAL.NS','KSCL.NS','MARKSANS.NS','LICHSGFIN.NS','CANFINHOME.NS','SASKEN.NS','HINDPETRO.NS','TIDEWATER.NS','HIL.NS','BALKRISIND.NS','NAVINFLUOR.NS']\n",
    "api_key = '####### HIDDEN CODE ##########'\n",
    "symbol = df_symbol_list_sql['symbol']\n",
    "idx = 0\n",
    "for x in symbol:\n",
    "    try:\n",
    "#     print(symbol)\n",
    "        newurl = api_key.replace('symbol',x)\n",
    "#         print(x)\n",
    "        with urllib.request.urlopen(newurl) as newurl:\n",
    "            data = json.loads(newurl.read().decode())\n",
    "#           print(data)\n",
    "            df_hist_price = pd.json_normalize(data['historical'])\n",
    "#           df_hist_price ['symbol'] = x   # This will add a new column to dataframe at last position by default\n",
    "            df_hist_price.insert(loc=idx, column='symbol', value=x) # This will add a new column at specific/required location\n",
    "#           dt = pd.DataFrame(data =[{'symbol':x,}])\n",
    "#           df_hist_price.head(10)\n",
    "            df_hist_price['date_added']= date.today()\n",
    "            saveToSQL(df_hist_price,\"historical_prices\",'append')\n",
    "    except Exception as val:\n",
    "        print(val)\n",
    "        continue\n",
    "print('Entire data is loaded')\n",
    "\n",
    "index_sql = \"CREATE INDEX idx_symbol ON mysql_portfolio.historical_prices (symbol(255));\"\n",
    "\n",
    "constraint_sql = \"\"\"\n",
    "ALTER TABLE mysql_portfolio.historical_prices\n",
    "ADD CONSTRAINT unique_historical_prices UNIQUE (symbol,open,adjClose);\n",
    "\"\"\"\n",
    "# Database connection\n",
    "engine = create_engine('####### HIDDEN CODE ############')\n",
    "\n",
    "# Execute SQL statements\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(index_sql)\n",
    "    connection.execute(constraint_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code to load income statement  - 1\n",
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "\n",
    "api_key = '##### HIDDEN CODE #####'\n",
    "symbol = df_symbol_list_sql['symbol']\n",
    "for x in symbol:\n",
    "    try:\n",
    "        newurl = api_key.replace('symbol',x)\n",
    "        api_data = connect_with_retry(newurl)\n",
    "        df_income_statement = api_data\n",
    "        df_income_statement = df_income_statement.replace(r'^\\s*$', np.NaN, regex=True) # This replaces special characters/Null/blank values with NaN\n",
    "        # df_income_statement['cik'] = df_income_statement['cik'].fillna(0) # This replaces NaN with 0\n",
    "#         df_income_statement\n",
    "        df_income_statement['date_added']= date.today()\n",
    "        saveToSQL(df_income_statement,\"income_statement\",'append')\n",
    "    except Exception as val:\n",
    "        print(val)\n",
    "        continue\n",
    "#     df_income_statement.append(df_income_statement)\n",
    "#     call_api(newurl)\n",
    "print('Entire Data loaded in table')\n",
    "\n",
    "# Adding index to table \n",
    "index_sql = \"CREATE INDEX idx_symbol ON mysql_portfolio.income_statement (symbol(255));\"\n",
    "\n",
    "# Adding unique constraint\n",
    "constraint_sql = \"\"\"\n",
    "ALTER TABLE mysql_portfolio.income_statement\n",
    "ADD CONSTRAINT unique_income_statement UNIQUE (symbol,reportedCurrency,calendarYear,revenue);\n",
    "\"\"\"\n",
    "# Database connection\n",
    "engine = create_engine('####### HIDDEN CODE ############')\n",
    "\n",
    "# Execute SQL statements\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(index_sql)\n",
    "    connection.execute(constraint_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to load balance sheet\n",
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "\n",
    "rowcount = 0\n",
    "api_key = '####### HIDDEN CODE ############'\n",
    "symbol = df_symbol_list_sql['symbol']\n",
    "\n",
    "for x in symbol:\n",
    "    try:\n",
    "        newurl = api_key.replace('symbol', x)\n",
    "        api_data = connect_with_retry(newurl)\n",
    "        df_balance_sheet = api_data\n",
    "\n",
    "        # Check if the DataFrame is empty\n",
    "        if df_balance_sheet.empty:\n",
    "            print(f\"Warning: No data found for symbol {x}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        df_balance_sheet = df_balance_sheet.replace(r'^\\s*$', np.NaN, regex=True)\n",
    "        # df_balance_sheet['cik'] = df_balance_sheet['cik'].fillna(0)\n",
    "        \n",
    "        df_balance_sheet['date_added'] = date.today()\n",
    "        saveToSQL(df_balance_sheet, \"balance_sheet\", 'append')\n",
    "    except Exception as val:\n",
    "        print(val)\n",
    "        continue\n",
    "\n",
    "print('Entire Data loaded in table')\n",
    "\n",
    "# Adding index to table \n",
    "index_sql = \"CREATE INDEX idx_symbol ON mysql_portfolio.balance_sheet (symbol(255));\"\n",
    "\n",
    "# Adding unique constraint\n",
    "constraint_sql = \"\"\"\n",
    "ALTER TABLE mysql_portfolio.balance_sheet\n",
    "ADD CONSTRAINT unique_balance_sheet UNIQUE (symbol,reportedCurrency,calendarYear,cashAndCashEquivalents);\n",
    "\"\"\"\n",
    "# Database connection\n",
    "engine = create_engine('####### HIDDEN CODE ############')\n",
    "\n",
    "# Execute SQL statements\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(index_sql)\n",
    "    connection.execute(constraint_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to load cash flow statement\n",
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "\n",
    "rowcount = 0\n",
    "####### HIDDEN CODE ############\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
